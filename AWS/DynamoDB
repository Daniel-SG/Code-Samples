DynamoDB
• Fully Managed, Highly available with replication across 3 AZ
• NoSQL database - not a relational database
• Scales to massive workloads, distributed database
• Millions of requests per seconds, trillions of row, 100s of TB of storage
• Fast and consistent in performance (low latency on retrieval)
• Integrated with IAM for security, authorization and administration
• Enables event driven programming with DynamoDB Streams
• Low cost and auto scaling capabilities
• Useful for key value data structure
• It is better to start on Demand and later on Provision Capacity
• If on demand is too expensive, probably Dynamo is not the best option or you
• Local index: Local indexes come with the constraint that all the records that share the same partition key need to fit in 10 GB, and once that allocation
  gets exhausted, all writes with that partition key will start failing. Unless you know for sure that you won’t ever exceed this limit, we recommend avoiding local indexes
• global indexes don’t constrain your table size in any way, the downside is if the provisioned throughput of a global index happens to be insufficient
  to keep up with updates on the main table, the internal queue can get full and then all operations will fail


DynamoDB - Basics
• DynamoDB is made of tables
• Each table has a primary key (must be decided at creation time) can be a single column (partition key) or combination (partition key + sort key)
• Each table can have an infinite number of items (= rows)
• Each item has attributes (can be added over time – can be null)
• Maximum size of a item is 400KB
• Data types supported are:
• Scalar Types: String, Number, Binary, Boolean, Null
• Document Types: List, Map
• Set Types: String Set, Number Set, Binary Set

DynamoDB – Provisioned Throughput
• Table must have provisioned read and write capacity units per second
• Eventually Consistent Read (default): If we read just after a write, it’s possible we’ll get unexpected response because of replication
• Strongly Consistent Read: If we read just after a write, we will get the correct data

• Read Capacity Units (RCU): throughput for reads ($0.00013 per RCU)
• 1 RCU = 1 strongly consistent read of 4 KB per second
• 1 RCU = 2 eventually consistent read of 4 KB per second
- Example 1: 10 strongly consistent reads per seconds of 4 KB each
	We need 10 * 4 KB / 4 KB = 10 RCU
- Example 2: 16 eventually consistent reads per seconds of 12 KB each
	We need (16 / 2) * ( 12 / 4 ) = 24 RCU
- Example 3: 10 strongly consistent reads per seconds of 6 KB each
	We need 10 * 8 KB / 4 = 20 RCU (we have to round up 6 KB to 8 KB)
	
• Write Capacity Units (WCU): throughput for writes ($0.00065 per WCU)
• 1 WCU = 1 write of 1 KB per second
If the items are larger than 1 KB, more WCU are consumed
-Example 1: we write 10 objects per seconds of 2 KB each.
	We need 2 * 10 = 20 WCU
-Example 2: we write 6 objects per second of 4.5 KB each
	We need 6 * 5 = 30 WCU (4.5 gets rounded to the upper KB)
-Example 3: we write 120 objects per minute of 2 KB each
	We need 120 / 60 * 2 = 4 WCU
• Option to setup auto-scaling of throughput to meet demand
• Throughput can be exceeded temporarily using “burst credit”
• If burst credit are empty, you’ll get a “ProvisionedThroughputException”.
• It’s then advised to do an exponential back-off retry
• Can use DAX accelerator to have faster troughput

DynamoDB - Partitions Internal
• Each partition:
	Max of 3000 RCU / 1000 WCU
	Max of 10GB
	
• To compute the number of partitions:
  By capacity: (TOTAL RCU / 3000) + (TOTAL WCU / 1000)
  By size: Total Size / 10 GB
 Total partitions = CEILING(MAX(Capacity, Size))
 
• WCU and RCU are spread evenly between partitions

AWS API Gateway
- to call lambda functions and others from the client
- support several environments

DynamoDB - Writing Data
• PutItem Write data to DynamoDB (create data or full replace) Consumes WCU
• UpdateItem Update data in DynamoDB (partial update of attributes)
   Possibility to use Atomic Counters and increase them
• Conditional Writes:
  Accept a write / update only if conditions are respected, otherwise reject
  Helps with concurrent access to items
  No performance impact
  
DynamoDB - DeleteItem
• Delete an individual row
    Ability to perform a conditional delete
    
• DeleteTable
  Delete a whole table and all its items
  Much quicker deletion than calling DeleteItem on all items
  
 DynamoDB - Batching Writes
 
•BatchWriteItem
  Up to 25 PutItem and / or DeleteItem in one call
  Up to 16 MB of data written
  Up to 400 KB of data per item
  Batching allows you to save in latency by reducing the number of API calls done against DynamoDB
  Operations are done in parallel for better efficiency
  It’s possible for part of a batch to fail, in which case we have the try the failed items (using exponential back off algorithm)
